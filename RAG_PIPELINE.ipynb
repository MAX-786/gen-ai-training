{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYH-rD6BuEzy"
      },
      "outputs": [],
      "source": [
        "! pip install -q --upgrade google-generativeai langchain-google-genai python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: create a .env file in the workspace\n",
        "# https://makersuite.google.com/\n",
        "\n",
        "!echo -e 'GOOGLE_API_KEY=AIzaSyCY3JgCLz0sqrR-No9N2czD-iE4A-w-Nnw' > .env"
      ],
      "metadata": {
        "id": "cvkP8X49y08b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrEVD45szYyc",
        "outputId": "24273181-918e-4298-caf8-394e93b184a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".  ..  .config\tdata  .env  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAptTup4zeKW",
        "outputId": "d1ff3998-e6cc-47d0-f4b3-f9f337bf1b42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "import textwrap\n",
        "\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ],
      "metadata": {
        "id": "j-Zqw97RziJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai"
      ],
      "metadata": {
        "id": "KTQkWGsKzmES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "genai.configure(api_key=os.environ.get(\"GOOGLE_API_KEY\"))"
      ],
      "metadata": {
        "id": "2gipQ-RHzoWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel(model_name = \"gemini-pro\")\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UJkoqVh0R4v",
        "outputId": "42ba5cd9-0235-4962-dc7a-65cb79e84e7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "genai.GenerativeModel(\n",
              "    model_name='models/gemini-pro',\n",
              "    generation_config={},\n",
              "    safety_settings={},\n",
              "    tools=None,\n",
              "    system_instruction=None,\n",
              "    cached_content=None\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = [\n",
        "    \"What is Mixture of Experts?\",\n",
        "]\n",
        "\n",
        "response = model.generate_content(prompt)"
      ],
      "metadata": {
        "id": "m9VUTVTP0Uk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "collapsed": true,
        "id": "nCPk_0At0fT3",
        "outputId": "d2023e1b-205e-44f6-ee86-936958ae029b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> **Mixture of Experts (MoE)**\n> \n> The Mixture of Experts (MoE) model is an ensemble learning technique that utilizes multiple specialized sub-models (experts) to make predictions. Instead of combining the sub-models' predictions through majority voting or averaging, MoE trains a gating network to determine the optimal weight for each expert for a given input.\n> \n> **How it Works:**\n> \n> 1. **Expert Sub-Models:** The MoE consists of multiple sub-models (experts) that are each specialized in solving a specific sub-task or capturing certain features of the data.\n> \n> 2. **Gating Network:** A separate gating network is trained to predict the weight (probability) of each expert on a given input. The gating network ensures that the experts contribute to the final prediction in a way that aligns with their individual strengths.\n> \n> 3. **Mixture Prediction:** The final prediction is a weighted sum of the predictions from each expert, with the weights determined by the gating network. This mixture model adapts dynamically to different inputs, allowing for more complex and tailored responses.\n> \n> **Advantages:**\n> \n> * **Increased Model Capacity:** MoE enhances model capacity by leveraging the collective knowledge of multiple experts, leading to improved accuracy and generalization.\n> * **Specialization and Flexibility:** Experts can be trained to address specific sub-tasks or capture different aspects of the data, resulting in a more specialized and flexible model.\n> * **Scalability:** MoE can be scaled up to large numbers of experts, increasing its predictive power and applicability to complex problems.\n> \n> **Applications:**\n> \n> MoE has been successfully applied in various domains, including:\n> \n> * Natural Language Processing (NLP)\n> * Computer Vision\n> * Speech Recognition\n> * Machine Translation\n> * Recommendation Systems"
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DcXu0jrZ0i98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Langchain\n"
      ],
      "metadata": {
        "id": "WlEgEFiD0x6h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI"
      ],
      "metadata": {
        "id": "AthU9kdw0236"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\")"
      ],
      "metadata": {
        "id": "wr7mJqQw1AVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = llm.invoke(\"What is Mixture of Experts?\")"
      ],
      "metadata": {
        "id": "Ifb3KUTu1D1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_markdown(result.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "collapsed": true,
        "id": "MQgidfGP1Lqw",
        "outputId": "ba66ce52-c3ac-4f16-a328-c436f4491160"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> **Mixture of Experts (MoE)**\n> \n> **Definition:**\n> \n> Mixture of Experts is a machine learning technique that combines multiple \"expert\" models to improve prediction accuracy. Each expert model is trained on a different subset of the data and specializes in a particular aspect of the problem.\n> \n> **Architecture:**\n> \n> * **Input:** A feature vector representing the input data.\n> * **Gating Network:** A neural network that determines the weights for each expert model.\n> * **Expert Models:** Multiple neural networks, each trained on a different subset of the data.\n> * **Output:** A weighted combination of the predictions from the expert models.\n> \n> **How it Works:**\n> \n> 1. The input data is passed through the gating network, which outputs a set of weights for each expert model.\n> 2. Each expert model makes a prediction based on its weighted input.\n> 3. The weighted predictions from the expert models are combined to produce the final output.\n> \n> **Advantages:**\n> \n> * **Improved accuracy:** MoE can achieve higher prediction accuracy by leveraging the specialized knowledge of multiple experts.\n> * **Robustness:** MoE is more robust to noise and outliers in the data because the predictions are based on a combination of models.\n> * **Scalability:** MoE can be scaled to handle large datasets by adding more expert models.\n> \n> **Applications:**\n> \n> MoE is used in a wide range of applications, including:\n> \n> * **Image classification:** By training expert models on different object categories.\n> * **Natural language processing:** By training expert models on different aspects of language, such as syntax and semantics.\n> * **Medical diagnosis:** By training expert models on different diseases and symptoms.\n> \n> **Related Techniques:**\n> \n> * **Weighted Ensemble Learning:** A simpler technique that combines multiple base models using fixed weights.\n> * **Hierarchical Mixture of Experts:** An extension of MoE where the expert models are organized in a hierarchical structure."
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GEMINI PRO VERSION\n"
      ],
      "metadata": {
        "id": "1cGegKmc1yLM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
        "# example\n",
        "message = HumanMessage(\n",
        "    content=[\n",
        "        {\n",
        "            \"type\": \"text\",\n",
        "            \"text\": \"What's in this image?\",\n",
        "        },\n",
        "        {\"type\": \"image_url\", \"image_url\": \"https://picsum.photos/seed/picsum/200/300\"},\n",
        "    ]\n",
        ")\n",
        "llm.invoke([message]).content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "8i_S7mjW11xy",
        "outputId": "5e306cea-ccab-41c8-aaf8-913e31d78a4c",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"That's a beautiful landscape photo!  It depicts a snow-covered mountain peak at either sunrise or sunset.  The sky is a soft pastel palette of pinks, oranges, and purples.  In the foreground, there's a gently sloping expanse of snow-covered land.  The overall feeling is one of serenity and vastness.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CHATS WITH DOCUMENTS\n"
      ],
      "metadata": {
        "id": "2MhA53rM288c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt -y -qq install tesseract-ocr libtesseract-dev\n",
        "\n",
        "!sudo apt-get -y -qq install poppler-utils libxml2-dev libxslt1-dev antiword unrtf poppler-utils pstotext tesseract-ocr flac ffmpeg lame libmad0 libsox-fmt-mp3 sox libjpeg-dev swig\n",
        "\n",
        "!pip install langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5nVz8qU3onY",
        "outputId": "aa226be4-4571-43e3-c384-059430083f6a",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "libtesseract-dev is already the newest version (4.1.1-2.1build1).\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 19 not upgraded.\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.18)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.34 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.34)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.6)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.5)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.37)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.11)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: numpy<2,>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.34->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-community"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDYZB-ix4Ja-",
        "outputId": "b4a093b2-94b4-44aa-d2dd-fa71fe31b1d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.17)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.34 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.34)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.18 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.18)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.37)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.11)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.0.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.7.1)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.5)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: numpy<2,>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.18->langchain-community) (0.3.6)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.18->langchain-community) (2.10.6)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.34->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.18->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.18->langchain-community) (2.27.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib\n",
        "import warnings\n",
        "from pathlib import Path as p\n",
        "from pprint import pprint\n",
        "\n",
        "import pandas as pd\n",
        "from langchain import PromptTemplate\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ],
      "metadata": {
        "id": "Wu2cJLLz3DiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Context Information Retreival"
      ],
      "metadata": {
        "id": "Yeh329pi4cXP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI"
      ],
      "metadata": {
        "id": "SQ_moTyN4jd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ChatGoogleGenerativeAI(model=\"gemini-pro\",\n",
        "                             temperature=0.3)"
      ],
      "metadata": {
        "id": "86LHKqX34p8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DOWNLOAD THE CONTENT\n"
      ],
      "metadata": {
        "id": "SJDEcNd04yYy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_folder = p.cwd() / \"data\"\n",
        "p(data_folder).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "pdf_url = \"https://services.google.com/fh/files/misc/practitioners_guide_to_mlops_whitepaper.pdf\"\n",
        "pdf_file = str(p(data_folder, pdf_url.split(\"/\")[-1]))\n",
        "\n",
        "urllib.request.urlretrieve(pdf_url, pdf_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZsDl3v64-ar",
        "outputId": "40c76ccd-ec09-4644-f08a-25d7840747b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/data/practitioners_guide_to_mlops_whitepaper.pdf',\n",
              " <http.client.HTTPMessage at 0x78b0a15f0e10>)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nKRQBMhcAYe_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXTRACT TEXT FROM PDF\n"
      ],
      "metadata": {
        "id": "9KowvPHY5FaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "645O3AQh5KiM",
        "outputId": "bb30028a-b9df-49ee-d102-9dc66d09d0f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.11/dist-packages (5.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_loader = PyPDFLoader(pdf_file)\n",
        "pages = pdf_loader.load_and_split()\n",
        "print(pages[3].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlUJNnmW5NQD",
        "outputId": "969be06c-033f-4753-c4ae-f5d724b80776",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n",
            "Organizations can use the framework to identify gaps in building an integrated ML platform and to focus on the scale \n",
            "and automate themes from Google’s AI Adoption Framework. The decision about whether (or to which degree) to \n",
            "adopt each of these processes and capabilities in your organization depends on your business context. For exam-\n",
            "ple, you must determine the business value that the framework creates when compared to the cost of purchasing or \n",
            "building capabilities (for example, the cost in engineering hours).\n",
            "Overview of MLOps lifecycle \n",
            "and core capabilities\n",
            "Despite the growing recognition of AI/ML as a crucial pillar of digital transformation, successful deployments and \n",
            "effective operations are a bottleneck for getting value from AI. Only one in two organizations has moved beyond \n",
            "pilots and proofs of concept. Moreover, 72% of a cohort of organizations that began AI pilots before 2019 have not \n",
            "been able to deploy even a single application in production.1 Algorithmia’s survey of the state of enterprise machine \n",
            "learning found that 55% of companies surveyed have not deployed an ML model.2 To summarize: models don’t make \n",
            "it into production, and if they do, they break because they fail to adapt to changes in the environment.\n",
            "This is due to a variety of issues. Teams engage in a high degree of manual and one-off work. They do not have reus-\n",
            "able or reproducible components, and their processes involve difficulties in handoffs between data scientists and IT. \n",
            "Deloitte identified lack of talent and integration issues as factors that can stall or derail AI initiatives.3 Algorithmia’s \n",
            "survey highlighted that challenges in deployment, scaling, and versioning efforts still hinder teams from getting value \n",
            "from their investments in ML. Capgemini Research noted that the top three challenges faced by organizations in \n",
            "achieving deployments at scale are lack of mid- to senior-level talent, lack of change-management processes, and \n",
            "lack of strong governance models for achieving scale.\n",
            "The common theme in these and other studies is that ML systems cannot be built in an ad hoc manner, isolated from \n",
            "other IT initiatives like DataOps and DevOps. They also cannot be built without adopting and applying sound software \n",
            "engineering practices, while taking into account the factors that make operationalizing ML different from operational-\n",
            "izing other types of software.\n",
            "Organizations need an automated and streamlined ML process. This process does not just help the organization \n",
            "successfully deploy ML models in production. It also helps manage risk when organizations scale the number of \n",
            "ML applications to more use cases in changing environments, and it helps ensure that the applications are still in \n",
            "line with business goals. McKinsey’s Global Survey on AI found that having standard frameworks and development \n",
            "1 The AI-powered enterprise, CapGemini Research Institute, 2020.\n",
            "2 2020 state of enterprise machine learning, Algorithmia, 2020.\n",
            "3 Artificial intelligence for the real world, Deloitte, 2017.\n",
            "4 The state of AI in 2020, McKinsey, 2020.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context = \"\\n\".join(str(p.page_content) for p in pages[:30])\n",
        "print(\"The total words in the context: \", len(context))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgArPdTo5Xnk",
        "outputId": "5126adb8-8be4-46ef-e1f4-10f82a0eecab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The total words in the context:  55372\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prompt Design - In Context"
      ],
      "metadata": {
        "id": "6REmDoW9OTAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = \"\"\"Answer the question as precise as possible using the provided context. If the answer is\n",
        "                    not contained in the context, say \"answer not available in context\" \\n\\n\n",
        "                    Context: \\n {context}?\\n\n",
        "                    Question: \\n {question} \\n\n",
        "                    Answer:\n",
        "                  \"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
        ")"
      ],
      "metadata": {
        "id": "YCKGrGvHOUNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stuff_chain = load_qa_chain(model, chain_type=\"stuff\", prompt=prompt)"
      ],
      "metadata": {
        "id": "Ok5jtzgwOQ3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What is Experimentation? Provide a detailed answer.\"\n",
        "\n",
        "\n",
        "stuff_answer = stuff_chain(\n",
        "    {\"input_documents\": pages[7:10], \"question\": question}, return_only_outputs=True\n",
        ")"
      ],
      "metadata": {
        "id": "FFwMBWNtOekb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(stuff_answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mR6MM8AOgR4",
        "outputId": "539ae2aa-a570-46f7-b007-deed241f5275"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'output_text': 'Experimentation is the core activity during the ML '\n",
            "                'development phase. Data scientists and ML researchers '\n",
            "                'prototype model architectures and training routines, create '\n",
            "                'labeled datasets, and use features and other reusable ML '\n",
            "                'artifacts that are governed through the data and model '\n",
            "                'management process. The primary output of this process is a '\n",
            "                'formalized training procedure, which includes data '\n",
            "                'preprocessing, model architecture, and model training '\n",
            "                'settings.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Describe data management and feature management systems.\"\n",
        "\n",
        "\n",
        "stuff_answer = stuff_chain(\n",
        "    {\"input_documents\": pages[7:10], \"question\": question}, return_only_outputs=True\n",
        ")\n",
        "\n",
        "pprint(stuff_answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlmOnaffOrvu",
        "outputId": "f499c83b-e6d0-4ac2-ab15-a9c84cac6ae7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'output_text': 'Answer not available in context'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k3dkyDFYOwUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7q76CHBkOwQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GgEWd5RGOwOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xWHNnAqLOwIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aG2P4U74Ov8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RAG Pipeline: Embedding + LLM\n"
      ],
      "metadata": {
        "id": "7DdCARd8DApt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-google-genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "JT4FA5OODTkb",
        "outputId": "79ca1353-3907-4913-9fec-c3baee50827a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.11/dist-packages (2.0.9)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (1.2.0)\n",
            "Requirement already satisfied: google-generativeai<0.9.0,>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (0.8.4)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.27 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (0.3.34)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (2.10.6)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.19.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.160.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (5.29.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.26.0)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-google-genai) (0.3.5)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-google-genai) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-google-genai) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-google-genai) (24.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google-genai) (2.27.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.66.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.9)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.27->langchain-google-genai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-google-genai) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-google-genai) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-google-genai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-google-genai) (0.23.0)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.70.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.62.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (3.2.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-google-genai) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-google-genai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-google-genai) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-google-genai) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-google-genai) (0.14.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-google-genai) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings"
      ],
      "metadata": {
        "id": "RZ-LXyjwDCHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000, chunk_overlap=0)\n",
        "context = \"\\n\\n\".join(str(p.page_content) for p in pages)\n",
        "texts = text_splitter.split_text(context)"
      ],
      "metadata": {
        "id": "mpjdkkUfDdKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# texts\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Iz5bKwm6KneE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")"
      ],
      "metadata": {
        "id": "_rGZj569KvGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chromadb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "fnnbtClSK1Ex",
        "outputId": "9bc1ef2e-fd5c-490b-9f54-2b34ab9aa3e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.11/dist-packages (0.6.3)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.2.2.post1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.10.6)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.7.6)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.115.8)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.26.4)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.11.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.12.2)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.20.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.30.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.0)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.70.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.2.1)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.15.1)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (32.0.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (9.0.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.0.2)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (5.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.15)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (24.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi>=0.95.2->chromadb) (0.45.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.1.24)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
            "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.5.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.66.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.30.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.30.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-asgi==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (2.27.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb) (0.28.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.4)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (14.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.10.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector_index = Chroma.from_texts(texts, embeddings).as_retriever()\n"
      ],
      "metadata": {
        "id": "LfQITrlRNtK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Describe data management and feature management systems.\"\n",
        "docs = vector_index.get_relevant_documents(question)"
      ],
      "metadata": {
        "id": "BFweRCsuN0dA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "d28SPX01N5LZ",
        "outputId": "2a4aa8b7-e68c-49dc-d93d-72f829c8083f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={}, page_content='26\\nThe serving engine can serve predictions to consumers in the following \\nforms:\\n• Online inference in near real time for high-frequency singleton \\nrequests (or mini batches of requests), using interfaces like REST \\nor gRPC.\\n• Streaming inference in near real time, such as through an \\nevent-processing pipeline.\\n• Offline batch inference for bulk data scoring, usually integrated \\nwith extract, transform, load (ETL) processes.\\n• Embedded inference as part of embedded systems or edge devic-\\nes.\\nIn some scenarios of prediction serving, the serving engine might need \\nto look up feature values that are related to the request. For example, you \\nmight have a model that predicts the propensity of a customer to buy a \\nparticular product, given a set of customer and product features. However, \\nthe request includes only the customer and the product identifier. There-\\nfore, the serving engine uses these identifiers to fetch the customer and \\nthe product feature values from a feature repository and then to feed them \\nto the model to produce a prediction.\\nAn important part of having confidence in ML systems is being able to \\ninterpret the models and provide explanations to their predictions. The \\nexplanations should provide insight into the rationale for the prediction—for \\nexample, by generating feature attributions for a given prediction. Feature \\nattributions indicate in the form of scores how much each feature contrib-\\nutes to a prediction.\\nThe inference logs and other serving metrics are stored for continuous \\nmonitoring and analysis.\\nContinuous monitoring\\nContinuous monitoring is the process of monitoring the effectiveness and \\nefficiency of a model in production, which is a crucial area of MLOps. It is \\nessential to regularly and proactively verify that the model performance \\ndoesn’t decay. As the serving data changes over time, its properties start \\nPrediction Serving\\nTypical assets produced in this \\nprocess include the following:\\n• Request-response payloads stored \\nin the serving logs store\\n• Feature attributions of the \\npredictions\\nCore MLOps capabilities:\\n• Dataset & feature repository\\n• Model serving\\n\\n27\\nto deviate from the properties data that was used for training and evaluating the model. This leads to model effective \\nperformance degradation. In addition, changes or errors in upstream systems that produce the prediction requests \\nmight lead to changes to the properties of the serving data, and consequently produce bad predictions from the \\nmodel.\\nThe monitoring engine uses the inference logs to identify anomalies (skews and outliers), as shown in figure 11.\\nA typical continuous monitoring process consists of the following steps:\\n1. A sample of the request-response payloads is captured and stored in the serving logs store.\\n2. The monitoring engine periodically loads the latest inference logs, generates a schema, and computes statis-\\ntics for the serving data.\\n3. The monitoring engine compares the generated schema to a reference schema to identify schema skews, \\nFigure 11. The continuous monitoring process\\n\\n28\\nand compares the computed statistics to baseline statistics to \\nidentify distribution skews.\\n4. If the true labels (ground truth) for the serving data are available, \\nthe monitoring engine uses it to evaluate the model predictive \\neffectiveness in hindsight on the serving data.\\n5. If anomalies are identified, or if the model’s performance is decay-\\ning, alerts can be pushed through various channels (for example, \\nemail or chat) to notify the owners to examine the model or to \\ntrigger a new retraining cycle. \\nEffectiveness performance monitoring aims to detect model decay. Model \\ndecay is usually defined in terms of data and concept drift.\\nData drift describes a growing skew between the dataset that was used to \\ntrain, tune, and evaluate the model and the production data that a model \\nreceives for scoring. Concept drift is an evolving relationship between the \\ninput predictors and the target feature.\\nData drift can involve two types of skews:\\n• Schema skew occurs when training data and serving data do not \\nconform to the same schema.\\n• Distribution skew occurs when the distribution of feature values \\nfor training data is significantly different from the distribution for \\nserving data.\\nIn addition to identifying schema and distribution skews, other techniques \\nfor detecting data and concept drift include novelty and outlier detection, \\nas well as feature attributions change. For more information, see ML model \\nmonitoring reference guides in the Google Cloud documentation.\\nIn some scenarios, your system is able to store ground truth for your serv-\\ning data. For example, you capture whether a customer bought a product \\nrecommended by your model, or you calculate the actual demand for a \\nparticular product by the end of the week compared to the demand that \\nwas forecasted by the model. You can use this information as true labels \\nto your serving data, and the information can be stored and retrieved from \\nthe dataset and feature repository for continuous evaluation and for further \\nmodel training cycles.\\nContinuous \\nMonitoring\\nTypical assets produced in this \\nprocess include the following:\\n• Anomalies detected in serving data \\nduring drift detection\\n• Evaluation metrics produced from \\ncontinuous evaluation\\nCore MLOps capabilities:\\n• Dataset & feature repository\\n• Model monitoring\\n• ML metadata & artifact repository\\n\\n29\\nBesides monitoring model effectiveness, monitoring model serving effi-\\nciency focuses on metrics like the following:\\n• Resource utilization, including CPUs, GPUs, and memory.\\n• Latency, which is a key metric in online and streaming deployments \\nto indicate model service health.\\n• Throughput, which is a key metric in all deployments.\\n• Error rates.\\nMeasuring these metrics is helpful not only in maintaining and improving \\nsystem performance, but also in predicting and managing costs.\\nData and model management\\nAt the heart of the six processes outlined earlier is data and model man-\\nagement. This is a central function for governing ML artifacts in order to \\nsupport auditability, traceability, and compliance, as well as for shareability, \\nreusability, and discoverability of ML assets.\\nDataset and feature management\\nOne of the key challenges of data science and ML is creating, maintaining, \\nand reusing high-quality data for training. Data scientists spend a signifi-\\ncant amount of their ML development time on exploratory data analysis, \\ndata preparation, and data transformation. However, other teams might \\nhave prepared the same datasets for similar use cases but have no means \\nfor sharing and reusing them. This situation can lead not only to wasted \\ntime re-creating the datasets, but to inconsistent definitions and instances \\nof the same data entities.\\nIn addition, during prediction serving, a common challenge is discrepancies \\nbetween serving data and training data. This is called training-serving skew, \\nand can occur because the data is extracted from different sources in dif-\\nferent forms during training and serving. Training-serving skew impacts the \\nperformance of the models in production.\\nDataset and feature management helps mitigate such issues by providing \\nData & Model \\nManagement \\nCore MLOps capabilities:\\n• Dataset & feature repository\\n• Model registry\\n• ML metadata & artifact repository\\n\\n30\\na unified repository for ML features and datasets. Figure 12 shows how the feature and dataset repository provides \\nthe same set of data entities for multiple uses in the MLOps environment.\\nAs the diagram shows, the features and datasets are created, discovered, and reused in different experiments. Batch \\nserving of the data is used for experimentation, continuous training, and batch prediction, while online serving of the \\ndata is used for real-time prediction use cases.\\nFeature management\\nFeatures are attributes of business entities that are cleansed and prepared based on standard business rules—ag-\\ngregations, derivations, flags, and so on. Examples of entities include product, customer, location, and promotion. \\nYou can manage your data entities in a centralized repository to standardize their definition, storage, and access for \\ntraining and serving. A feature repository helps data scientists and researchers do the following:\\n• Discover and reuse available feature sets for their entities instead of re-creating the entities in order to create \\nFigure 12. Using the dataset and feature repository to provide entities for multiple uses'),\n",
              " Document(metadata={}, page_content='31\\ntheir own datasets.\\n• Establish a central definition of features.\\n• Avoid training-serving skew by using the feature repository as the data source for experimentation, continu-\\nous training, and online serving.\\n• Serve up-to-date feature values from the feature repository.\\n• Provide a way of defining and sharing new entities and features.\\n• Improve collaboration between data science and research teams by sharing features.\\nIn batch ETL systems, the training pipeline can retrieve the features as a batch for the training task. For online serv-\\ning, the serving engine can fetch the feature values that are related to the requested entity. Updates to the feature \\nrepository can be ingested from the batch ETL or streaming systems. In addition to those updates, the monitoring \\nservice can update statistics and metrics for these features.\\nDataset management\\nFeatures can be used in many datasets for multiple ML tasks and use cases, while a dataset is used for a particular \\nML task or use case. More precisely, feature repositories typically don’t include labeled data instances (instances \\nwith predictable targets). Instead, they include reusable feature values of various entities. The features of different \\nentities can be combined and joined with other transactional data that contains labels in order to create a dataset.\\nFor example, the feature repository might contain a customer entity that includes features that describe customer \\ndemographics, purchase behavior, social media interactions, sentiment scores, third-party financial flags, and so on. \\nThe customer entity can be used in several tasks, such as churn prediction, click-through rate prediction, customer \\nlifetime value estimation, customer segmentation, and recommendations. Each task has its own dataset that con-\\ntains the customer features and other features from the entities that are relevant to the task. In addition, in case of \\nsupervised learning tasks, each dataset has its own labels.\\nDataset management helps with the following:\\n• Maintaining scripts for creating datasets and splits so that datasets can be created in different environments \\n(development, test, production, and so on).\\n• Maintaining a single dataset definition and realization within the team to use in various model implementa-\\ntions and hyperparameters. This dataset includes splits (training, evaluation, test, and so on) and filtering \\nconditions.\\n• Maintaining metadata and annotation that can be useful for team members who are collaborating on the \\nsame dataset and task.\\n• Providing reproducibility and lineage tracking.\\n\\n32\\nModel management\\nAs organizations add to the number of models in production at scale, it becomes difficult to keep track of all of them \\nmanually. Organizations need controls in order to manage risk and implement ML models responsibility, as well as to \\nmaintain compliance with regulations. \\nTo help with this task, organizations need to establish robust model management. Model management is a \\ncross-cutting process that is at the center of MLOps. It entails both ML metadata tracking and model governance. \\nHaving model management across the ML lifecycle helps ensure the following:\\n• The data that is being collected and used for model training and evaluation is accurate, unbiased, and used \\nappropriately without any data privacy violations.\\n• The models are evaluated and validated against effectiveness quality measures and fairness indicators, so \\nthat they are fit for deployment in production.\\n• The models are interpretable, and their outcomes are explainable (if needed).\\n• The performance of deployed models is monitored using continuous evaluation and the models’ perfor-\\nmance metrics are tracked and reported. \\n• Potential issues in model training or prediction serving are traceable, debuggable, and reproducible.\\nML metadata tracking\\nFigure 13. Metadata tracking\\n\\n33\\nML metadata tracking is generally integrated with different MLOps processes. The artifacts produced by the other \\nprocesses are usually automatically stored in an ML artifact repository, along with the information about the process \\nexecutions. ML metadata that is captured can include pipeline run ID, trigger, process type, step, start and end date-\\ntime, status, environment configurations, and input parameter values. Examples of artifacts that are stored include \\nprocessed data splits, schemas, statistics, hyperparameters, models, and evaluation metrics or custom artifacts. \\nFigure 13 shows metadata tracking.\\nML metadata tracking lets data scientists and ML engineers track experimentation parameters and pipeline config-\\nurations for reproducibility and for tracing lineage. In addition, ML metadata tracking lets users search, discover, and \\nexport existing ML models and artifacts. \\nData scientists and ML engineers can use ML metadata tracking to add and update annotations to the tracked ML \\nexperiments and runs. This facilitates discoverability. Moreover, ML metadata tracking provides the tools for analyz-\\ning, comparing, and visualizing the metadata and artifacts of different experiments and ML pipeline runs. This helps \\ndata scientists and ML engineers understand the behavior of the pipelines and to debug ML issues.\\nModel governance\\nModel governance is about registering, reviewing, validating, and approving models for deployment. Depending on \\nthe organization, on the regulatory requirements of the model, and on the particular use case, the process of model \\ngovernance can differ. The process can be automated, semi-automated, or fully automated (with multiple release \\ncriteria in all cases) to determine whether ML models are ready to go to production. In addition, model governance \\nshould support reporting on the performance of deployed models.\\nFigure 14. Tasks involved in model governance\\n\\n34\\nFigure 14 shows the tasks that are involved in model governance.\\nModel governance can use information in the ML metadata and the model registry to do the following tasks:\\n• Store: Add or update model properties and track model versions and property changes. The model registry can \\nstore many model versions from the experimentation and continuous training phases, which lets data scientists \\neasily reproduce significant models.\\n• Evaluate: Compare a new challenger model to the champion model by looking not only at evaluation metrics \\n(accuracy, precision, recall, specificity, and so on) but also at business KPIs that are collected through online ex-\\nperimentation. Additionally, model owners need to be able to understand and explain the model predictions—for \\nexample, by using feature attribution methods. This ensures the quality of the model that is deployed in produc-\\ntion.\\n• Check: Review, request changes, and approve the model to help control for risks, such as business, financial, \\nlegal, security, privacy, reputational, and ethical concerns.\\n• Release: Invoke the model deployment process to go live. This controls the type of the model release (for exam-\\nple, canary or blue-green) and the traffic split that is directed to it.\\n• Report: Aggregate, visualize, and highlight model performance metrics that are collected from the continuous \\nevaluation process. This ensures the quality of the model in production.\\nExplainability is particularly important in the case of decision automation. The governance process should provide \\nto risk managers and auditors a clear view of lineage and accountability. The process should also provide them the \\nability to review decisions in accordance with an organization’s ethical and legal responsibilities.\\nPutting it all together\\nDelivering business value through ML is not only about building the best ML model for the use case at hand. Deliver-\\ning this value is also about building an integrated ML system that operates continuously to adapt to changes in the \\ndynamics of the business environment. Such an ML system involves collecting, processing, and managing ML data-\\nsets and features; training, and evaluating models at scale; serving the model for predictions; monitoring the model \\nperformance in production; and tracking model metadata and artifacts.\\nIn this document, we discuss the core capabilities for building and operating ML systems, and we describe a com-\\nprehensive MLOps process to streamline the workflow from development to production. This can help organizations \\nreduce time to market while increasing the reliability, performance, scalability, and security of their ML systems. \\nFigure 15 provides a summary of the end-to-end MLOps process.\\n\\n35\\nFigure 15. End-to-end MLOps workflow\\n\\n36\\nAdditional resources\\nFor more information about how to get started with MLOps on Google Cloud, see the following books, guides, cours-\\nes, articles, and videos:\\n• Best Practices for Implementing Machine Learning on Google Cloud\\n• Machine Learning Design Patterns: Solutions to Common Challenges in Data Preparation, Model Building, \\nand MLOps\\n• An introduction to MLOps on Google Cloud\\n• MLOps: Continuous delivery and automation pipelines in machine learning\\n• Architecture for MLOps using TFX, Kubeflow Pipelines, and Cloud Build\\n• Setting up an MLOps environment on Google Cloud\\n• MLOps (Machine Learning Operations) Fundamentals on Coursera'),\n",
              " Document(metadata={}, page_content='6\\nquired for a robust MLOps implementation.\\nBuilding an ML-enabled system\\nBuilding an ML-enabled system is a multifaceted undertaking that combines data engineering, ML engineering, and \\napplication engineering tasks, as shown in figure 1.\\nData engineering involves ingesting, integrating, curating, and refining data to facilitate a broad spectrum of opera-\\ntional tasks, data analytics tasks, and ML tasks. Data engineering can be crucial to the success of the analytics and \\nML initiatives. If an organization does not have robust data engineering processes and technologies, it might not be \\nset up for success with downstream business intelligence, advanced analytics, or ML projects.\\nML models are built and deployed in production using curated data that is usually created by the data engineering \\nteam. The models do not operate in silos; they are components of, and support, a large range of application systems, \\nsuch as business intelligence systems, line of business applications, process control systems, and embedded sys-\\ntems. Integrating an ML model into an application is a critical task that involves making sure first that the deployed \\nmodel is used effectively by the applications, and then monitoring model performance. In addition to this, you should \\nalso collect and monitor relevant business KPIs (for example, click-through rate, revenue uplift, and user experience). \\nThis information helps you understand the impact of the ML model on the business and adapt accordingly.\\nFigure 1. The relationship of data engineering, ML engineering, and app engineering\\n\\n7\\nThe MLOps lifecycle\\nThe MLOps lifecycle encompasses seven integrated and iterative processes, as shown in figure 2.\\nThe processes can consist of the following:\\n• ML development concerns experimenting and developing a robust and reproducible model training proce-\\ndure (training pipeline code), which consists of multiple tasks from data preparation and transformation to \\nmodel training and evaluation.\\n• Training operationalization concerns automating the process of packaging, testing, and deploying repeat-\\nable and reliable training pipelines.\\n• Continuous training concerns repeatedly executing the training pipeline in response to new data or to code \\nchanges, or on a schedule, potentially with new training settings.\\n• Model deployment concerns packaging, testing, and deploying a model to a serving environment for online \\nexperimentation and production serving.\\nFigure 2. The MLOps lifecycle\\n\\n8\\n• Prediction serving is about serving the model that is deployed in production for inference.\\n• Continuous monitoring is about monitoring the effectiveness and efficiency of a deployed model.\\n• Data and model management is a central, cross-cutting function for governing ML artifacts to support audit-\\nability, traceability, and compliance. Data and model management can also promote shareability, reusability, \\nand discoverability of ML assets.\\nMLOps: An end-to-end workflow\\nFigure 3 shows a simplified but canonical flow for how the MLOps processes interact with each other, focusing on \\nhigh-level flow of control and on key inputs and outputs.\\nThis is not a waterfall workflow that has to sequentially pass through all the processes. The processes can be \\nskipped, or the flow can repeat a given phase or a subsequence of the processes. The diagram shows the following \\nflow:\\n1. The core activity during this ML development phase is experimentation. As data scientists and ML research-\\ners prototype model architectures and training routines, they create labeled datasets, and they use features \\nand other reusable ML artifacts that are governed through the data and model management process. The \\nFigure 3. The MLOps process\\n\\n9\\nprimary output of this process is a formalized training procedure, which includes data preprocessing, model \\narchitecture, and model training settings. \\n2. If the ML system requires continuous training (repeated retraining of the model), the training procedure is \\noperationalized as a training pipeline. This requires a CI/CD routine to build, test, and deploy the pipeline to \\nthe target execution environment.\\n3. The continuous training pipeline is executed repeatedly based on retraining triggers, and it produces a model \\nas output. The model is retrained as new data becomes available, or if model performance decay is detected. \\nOther training artifacts and metadata that are produced by a training pipeline are also tracked. If the pipeline \\nproduces a successful model candidate, that candidate is then tracked by the model management process \\nas a registered model. \\n4. The registered model is annotated, reviewed, and approved for release and is then deployed to a production \\nenvironment. This process might be relatively opaque if you are using a no-code solution, or it can involve \\nbuilding a custom CI/CD pipeline for progressive delivery. \\n5. The deployed model serves predictions using the deployment pattern that you have specified: online, batch, \\nor streaming predictions. In addition to serving predictions, the serving runtime can generate model explana-\\ntions and capture serving logs to be used by the continuous monitoring process. \\n6. The continuous monitoring process monitors the model for predictive effectiveness and service. The primary \\nconcern of effectiveness performance monitoring is detecting model decay—for example, data and concept \\ndrift. The model deployment can also be monitored for efficiency metrics like latency, throughput, hardware \\nresource utilization, and execution errors. \\nMLOps capabilities\\nTo effectively implement the key MLOps processes outlined in the previous section, organizations need to establish a \\nset of core technical capabilities. These capabilities can be provided by a single integrated ML platform. Alternative-\\nly, they can be created by combining vendor tools that each are best suited to particular tasks, developed as custom \\nservices, or created as a combination of these approaches.\\nIn most cases, the processes are deployed in stages rather than all at once in a single deployment. An organization’s \\nplan for adopting these processes and capabilities should align with business priorities and with the organization’s \\ntechnical and skills maturity. For example, many organizations start by focusing on the processes for ML develop-\\nment, model deployment, and prediction serving. For these organizations, continuous training and continuous moni-\\ntoring might not be necessary if they are piloting a relatively small number of ML systems.\\nFigure 4 shows the core set of technical capabilities that are generally required for MLOps. They are abstracted as \\nfunctional components that can have many-to-many mappings to specific products and technologies.\\n\\n10\\nSome foundational capabilities are required in order to support any IT workload, such as a reliable, scalable, and \\nsecure compute infrastructure. Most organizations already have investments in these capabilities and can benefit by \\ntaking advantage of them for ML workflows. Such capabilities might span multiple clouds, or even operate partially \\non-premises. Ideally, this would include advanced capabilities such as specialized ML accelerators.\\nIn addition, an organization needs standardized configuration management and CI/CD capabilities to build, test, \\nrelease, and operate software systems rapidly and reliably, including ML systems.\\nOn top of these foundational capabilities is a set of core MLOps capabilities. These include experimentation, data \\nprocessing, model training, model evaluation, model serving, online experimentation, model monitoring, ML pipeline, \\nand model registry. Finally, two cross-cutting capabilities that enable integration and interaction are an ML metadata \\nand artifact repository and an ML dataset and feature repository.\\nFigure 4. Core MLOps technical capabilities\\n\\n11\\nThe following sections outline the characteristics of each of the MLOps capabilities.\\nExperimentation \\nThe experimentation capability lets your data scientists and ML researchers collaboratively perform exploratory data \\nanalysis, create prototype model architectures, and implement training routines. An ML environment should also let \\nthem write modular, reusable, and testable source code that is version controlled. Key functionalities in experimenta-\\ntion include the following:\\n• Provide notebook environments that are integrated with version control tools like Git.\\n• Track experiments, including information about the data, hyperparameters, and evaluation metrics for \\nreproducibility and comparison.\\n• Analyze and visualize data and models.\\n• Support exploring datasets, finding experiments, and reviewing implementations.\\n• Integrate with other data services and ML services in your platform.\\nData processing\\nThe data processing capability lets you prepare and transform large amounts of data for ML at scale in ML develop-\\nment, in continuous training pipelines, and in prediction serving. Key functionalities in data processing include the \\nfollowing:\\n• Support interactive execution (for example, from notebooks) for quick experimentation and for long-running \\njobs in production.\\n• Provide data connectors to a wide range of data sources and services, as well as data encoders and \\ndecoders for various data structures and formats.\\n• Provide both rich and efficient data transformations and ML feature engineering for structured (tabular) and \\nunstructured data (text, image, and so on).\\n• Support scalable batch and stream data processing for ML training and serving workloads.\\nModel training\\nThe model training capability lets you efficiently and cost-effectively run powerful algorithms for training ML models.'),\n",
              " Document(metadata={}, page_content='12\\nModel training should be able to scale with the size of both the models and the datasets that are used for training. \\nKey functionalities in model training include the following:\\n• Support common ML frameworks and support custom runtime environments.\\n• Support large-scale distributed training with different strategies for multiple GPUs and multiple workers.\\n• Enable on-demand use of ML accelerators.\\n• Allow efficient hyperparameter tuning and target optimization at scale.\\n• Ideally, provide built-in automated ML (AutoML) functionality, including automated feature selection and engi-\\nneering as well as automated model architecture search and selection.\\nModel evaluation\\nThe model evaluation capability lets you assess the effectiveness of your model, interactively during experimentation \\nand automatically in production. Key functionalities in model evaluation include the following:\\n• Perform batch scoring of your models on evaluation datasets at scale.\\n• Compute pre-defined or custom evaluation metrics for your model on different slices of the data.\\n• Track trained-model predictive performance across different continuous-training executions.\\n• Visualize and compare performances of different models.\\n• Provide tools for what-if analysis and for identifying bias and fairness issues.\\n• Enable model behavior interpretation using various explainable AI techniques.\\nModel serving\\nThe model serving capability lets you deploy and serve your models in production environments. Key functionalities \\nin model serving include the following:\\n• Provide support for low-latency, near-real-time (online) prediction and high-throughput batch (offline) \\nprediction.\\n• Provide built-in support for common ML serving frameworks (for example, TensorFlow Serving, TorchServe, \\nNvidia Triton, and others for Scikit-learn and XGBoost models) and for custom runtime environments.\\n• Enable composite prediction routines, where multiple models are invoked hierarchically or simultaneously \\nbefore the results are aggregated, in addition to any required pre- or post-processing routines.\\n• Allow efficient use of ML inference accelerators with autoscaling to match spiky workloads and to balance\\n\\n13\\ncost with latency.\\n• Support model explainability using techniques like feature attributions for a given model prediction.\\n• Support logging of prediction serving requests and responses for analysis. \\nOnline experimentation\\nThe online experimentation capability lets you understand how newly trained models perform in production settings \\ncompared to the current models (if any) before you release the new model to production. For example, using a small \\nsubset of the serving population, you use online experimentation to understand the impact that a new recommen-\\ndation system has on click-throughs and on conversation rates. The results of online experimentation should be \\nintegrated with the model registry capability to facilitate the decision about releasing the model to production. Online \\nexperimentation enhances the reliability of your ML releases by helping you decide to discard ill-performing models \\nand to promote well-performing ones. Key functionalities in online experimentation include the following:\\n• Support canary and shadow deployments.\\n• Support traffic splitting and A/B tests.\\n• Support multi-armed bandit (MAB) tests.\\nModel monitoring\\nThe model monitoring capability lets you track the efficiency and effectiveness of the deployed models in production \\nto ensure predictive quality and business continuity. This capability informs you if your models are stale and need to \\nbe investigated and updated. Key functionalities in model monitoring include the following:\\n• Measure model efficiency metrics like latency and serving-resource utilization.\\n• Detect data skews, including schema anomalies and data and concept shifts and drifts.\\n• Integrate monitoring with the model evaluation capability for continuously assessing the effectiveness \\nperformance of the deployed model when ground truth labels are available. \\nML pipelines\\nThe ML pipelines capability lets you instrument, orchestrate, and automate complex ML training and prediction pipe-\\n\\n14\\nlines in production. ML workflows coordinate different components, where each component performs a specific task \\nin the pipeline. Key functionalities in ML pipelines include the following:\\n• Trigger pipelines on demand, on a schedule, or in response to specified events.\\n• Enable local interactive execution for debugging during ML development.\\n• Integrate with the ML metadata tracking capability to capture pipeline execution parameters and to produce \\nartifacts.\\n• Provide a set of built-in components for common ML tasks and also allow custom components.\\n• Run on different environments, including local machines and scalable cloud platforms.\\n• Optionally, provide GUI-based tools for designing and building pipelines.\\nModel registry\\nThe model registry capability lets you govern the lifecycle of the ML models in a central repository. This ensures the \\nquality of the production models and enables model discovery. Key functionalities in the model registry include the \\nfollowing:\\n• Register, organize, track, and version your trained and deployed ML models.\\n• Store model metadata and runtime dependencies for deployability.\\n• Maintain model documentation and reporting—for example, using model cards.\\n• Integrate with the model evaluation and deployment capability and track online and offline evaluation metrics \\nfor the models.\\n• Govern the model launching process: review, approve, release, and roll back. These decisions are based on a \\nnumber of offline performance and fairness metrics and on online experimentation results.\\nDataset and feature repository\\nThe dataset and feature repository capability lets you unify the definition and the storage of the ML data assets. \\nHaving a central repository of fresh, high-quality data assets enables shareability, discoverability, and reusability. The \\nrepository also provides data consistency for training and inference. This helps data scientists and ML researchers \\nsave time on data preparation and feature engineering, which typically take up a significant amount of their time. Key \\nfunctionalities in the data and feature repository include the following:\\n\\n15\\n• Enable shareability, discoverability, reusability, and versioning of data assets.\\n• Allow real-time ingestion and low-latency serving for event streaming and online prediction workloads. \\n• Allow high-throughput batch ingestion and serving for extract, transform, load (ETL) processes and model \\ntraining, and for scoring workloads.\\n• Enable feature versioning for point-in-time queries.\\n• Support various data modalities, including tabular data, images, and text.\\nML data assets can be managed at the entity features level or at the full dataset level. For example, a feature reposi-\\ntory might contain an entity called customer, which includes features like age group, postal code, and gender. On the \\nother hand, a dataset repository might include a customer churn dataset, which includes features from the customer \\nand product entities, as well as purchase- and web-activity event logs.\\nML metadata and artifact tracking\\nVarious types of ML artifacts are produced in different processes of the MLOps lifecycle, including descriptive \\nstatistics and data schemas, trained models, and evaluation results. ML metadata is the information about these \\nartifacts, including their location, types, properties, and associations to experiments and runs. The ML metadata and \\nartifact tracking capability is foundational to all other MLOps capabilities. Such a capability enables reproducibility \\nand debugging of complex ML tasks and pipelines. Key functionalities in ML metadata and artifact tracking include \\nthe following:\\n• Provide traceability and lineage tracking of ML artifacts.\\n• Share and track experimentation and pipeline parameter configurations.\\n• Store, access, investigate, visualize, download, and archive ML artifacts.\\n• Integrate with all other MLOps capabilities.\\nDeep dive of MLOps processes\\nThis section describes each of the core MLOps processes in detail. It describes key tasks and flow of control be-\\ntween tasks, the key artifacts created by the tasks, and the relationship of tasks to other upstream and downstream \\nprocesses. In this section, you learn about concrete details of tasks like running a continuous training pipeline, de-\\nploying a model, and monitoring predictive performance of the model.\\n\\n16\\nMLOps processes take place on an integrated ML platform that has the required development and operations capa-\\nbilities (described later). Infrastructure engineers can provision this type of platform in different environments (like \\ndevelopment, test, staging, and production) using configuration management and infrastructure-as-code (IaC) tools \\nlike Terraform. Each environment is configured with its own set of required compute resources, data access, and \\nsubset of MLOps capability services.\\nML development\\nExperimentation is the core activity in ML development, where your data scientists can rapidly try several ideas for \\ndata preparation and ML modeling. Experimentation starts when the ML use case is well defined, meaning that the \\nfollowing questions have been answered:\\n• What is the task?\\n• How can we measure business impact?\\n• What is the evaluation metric?\\nFigure 5. The ML development process')]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stuff_answer = stuff_chain(\n",
        "    {\"input_documents\": docs, \"question\": question}, return_only_outputs=True\n",
        ")"
      ],
      "metadata": {
        "id": "ILfjvtu3OBUX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(stuff_answer)"
      ],
      "metadata": {
        "id": "6ZkzTqQXO5jZ",
        "outputId": "4def21c8-f781-4a88-d7bb-842e5c5a28d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'output_text': 'Data and feature management helps mitigate such issues by '\n",
            "                'providing \\n'\n",
            "                'a unified repository for ML features and datasets. Figure 12 '\n",
            "                'shows how the feature and dataset repository provides \\n'\n",
            "                'the same set of data entities for multiple uses in the MLOps '\n",
            "                'environment.\\n'\n",
            "                'As the diagram shows, the features and datasets are created, '\n",
            "                'discovered, and reused in different experiments. Batch \\n'\n",
            "                'serving of the data is used for experimentation, continuous '\n",
            "                'training, and batch prediction, while online serving of the \\n'\n",
            "                'data is used for real-time prediction use cases.\\n'\n",
            "                'Feature management\\n'\n",
            "                'Features are attributes of business entities that are '\n",
            "                'cleansed and prepared based on standard business rules—ag-\\n'\n",
            "                'gregations, derivations, flags, and so on. Examples of '\n",
            "                'entities include product, customer, location, and '\n",
            "                'promotion. \\n'\n",
            "                'You can manage your data entities in a centralized repository '\n",
            "                'to standardize their definition, storage, and access for \\n'\n",
            "                'training and serving. A feature repository helps data '\n",
            "                'scientists and researchers do the following:\\n'\n",
            "                '• Discover and reuse available feature sets for their '\n",
            "                'entities instead of re-creating the entities in order to '\n",
            "                'create \\n'\n",
            "                'their own datasets.\\n'\n",
            "                '• Establish a central definition of features.\\n'\n",
            "                '• Avoid training-serving skew by using the feature repository '\n",
            "                'as the data source for experimentation, continu-\\n'\n",
            "                'ous training, and online serving.\\n'\n",
            "                '• Serve up-to-date feature values from the feature '\n",
            "                'repository.\\n'\n",
            "                '• Provide a way of defining and sharing new entities and '\n",
            "                'features.\\n'\n",
            "                '• Improve collaboration between data science and research '\n",
            "                'teams by sharing features.\\n'\n",
            "                'In batch ETL systems, the training pipeline can retrieve the '\n",
            "                'features as a batch for the training task. For online serv-\\n'\n",
            "                'ing, the serving engine can fetch the feature values that are '\n",
            "                'related to the requested entity. Updates to the feature \\n'\n",
            "                'repository can be ingested from the batch ETL or streaming '\n",
            "                'systems. In addition to those updates, the monitoring \\n'\n",
            "                'service can update statistics and metrics for these '\n",
            "                'features.\\n'\n",
            "                'Dataset management\\n'\n",
            "                'Features can be used in many datasets for multiple ML tasks '\n",
            "                'and use cases, while a dataset is used for a particular \\n'\n",
            "                'ML task or use case. More precisely, feature repositories '\n",
            "                'typically don’t include labeled data instances (instances \\n'\n",
            "                'with predictable targets). Instead, they include reusable '\n",
            "                'feature values of various entities. The features of '\n",
            "                'different \\n'\n",
            "                'entities can be combined and joined with other transactional '\n",
            "                'data that contains labels in order to create a dataset.\\n'\n",
            "                'For example, the feature repository might contain a customer '\n",
            "                'entity that includes features that describe customer \\n'\n",
            "                'demographics, purchase behavior, social media interactions, '\n",
            "                'sentiment scores, third-party financial flags, and so on. \\n'\n",
            "                'The customer entity can be used in several tasks, such as '\n",
            "                'churn prediction, click-through rate prediction, customer \\n'\n",
            "                'lifetime value estimation, customer segmentation, and '\n",
            "                'recommendations. Each task has its own dataset that con-\\n'\n",
            "                'tains the customer features and other features from the '\n",
            "                'entities that are relevant to the task. In addition, in case '\n",
            "                'of \\n'\n",
            "                'supervised learning tasks, each dataset has its own labels.\\n'\n",
            "                'Dataset management helps with the following:\\n'\n",
            "                '• Maintaining scripts for creating datasets and splits so '\n",
            "                'that datasets can be created in different environments \\n'\n",
            "                '(development, test, production, and so on).\\n'\n",
            "                '• Maintaining a single dataset definition and realization '\n",
            "                'within the team to use in various model implementa-\\n'\n",
            "                'tions and hyperparameters. This dataset includes splits '\n",
            "                '(training, evaluation, test, and so on) and filtering \\n'\n",
            "                'conditions.\\n'\n",
            "                '• Maintaining metadata and annotation that can be useful for '\n",
            "                'team members who are collaborating on the \\n'\n",
            "                'same dataset and task.\\n'\n",
            "                '• Providing reproducibility and lineage tracking.'}\n"
          ]
        }
      ]
    }
  ]
}